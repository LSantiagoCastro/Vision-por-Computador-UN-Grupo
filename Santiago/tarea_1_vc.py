# -*- coding: utf-8 -*-
"""Tarea 1_VC

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10cPJLiAJhCzgwQZinFzj87_dkXnsyMq7

#TAREA. VISION POR COMPUTADORA
Leonar Santiago Castro Vizcaya

#1. Operaciones mas importantes soportadas en Numpy
"""

import numpy as np
from math import pi
import matplotlib.pyplot as plt

"""##Trigonometricas:

"""

x = np.random.randint(0,360, (4,4))
x

# np.radians(x) Convierte angulos de grados a radianes # np.degrees(x) convierte de radianes a grados
x = np.radians(x)
x

########### sin(x), cos(x), tan(x), arcsin(x), arcos(x), arctan(x), tambien las hiperbolicas  ###########
tan = np.tan(x)
tan

"""##Rounding  (Redondeo):

"""

# np.round(tan, 1) Redondea los datos de un arreglo al numero de decimales dado (1)
round=np.round(tan, 1)
round

# np.rint(x) redondea los datos al numero entero mas cercano
np.rint(round)

#np.floor(round) devuelve el "piso" o el entero directamente menor 
np.floor(round)

#np.ceil(round) devuelve el "cielo" o el entero directamente mayor
np.ceil(round)

#np.trunc(round) devuelve enteros, omitiendo la parte decimal de los datos

t = np.trunc(round)
print(round, "\n",  t)

"""##Suma, Productos y diferencias:"""

#np.sum(arr, axis) suma los elementos de una matriz por filas(axis = 1) o columnas (axis = 0)
np.sum(t, axis = 1)

#np.nanprod(t) Devuelve el producto de los elementos de la matriz sobre un eje determinado
np.nanprod(t, 0)

#np.diff Calcula la n-ésima diferencia discreta a lo largo del eje dado: out[i] = a[i+1] - a[i]
print(t,"\n", (np.diff(t, axis=0)))

#np.diff Calcula la n-ésima diferencia discreta a lo largo del eje dado: out[i] = a[i+1] - a[i]
t=np.random.randint(0,10,(1,10))
print(t,"\n", (np.diff(t, n=1, axis=1)))

#np.gradient(t) evuelve el gradiente de una matriz N-dimensional.
x = np.array([0, 1, 2, 3, 4])
f = x**2
np.gradient(f, edge_order=1)

#np.cross(x,y) producto cruzado de vectores
x = [1, 2, 3]
y = [4, 5, 6]
np.cross(x, y)

x = np.array([[1,2,3], [4,5,6]])
y = np.array([[4,5,6], [1,2,3]])
np.cross(x, y)

#np.trapz(y,x) Integral definida de 'y' = arreglo n-dimensional aproximado a lo largo de un solo eje por la regla trapezoidal.
a = np.arange(6).reshape(2, 3)
a

np.trapz(a, axis=0)

np.trapz(a, axis=1)

"""##Exponentes y logaritmos:

"""

X = ([1, 2, 3, 4],[5, 6, 7, 8],[9, 10, 11, 12],[13, 14, 15, 16])
X = np.array(X)
X

np.exp(X)

#Calcule 2**p para todo p en la matriz de entrada.
Y = np.exp2(X)
print(X, "\n" , np.round_(Y, decimals = 2))

np.log(X) #Logaritmo natural, por elementos.

np.log10(X)



"""##Algebra Lineal:
numpy.linalg
"""

A = ([1, 2, 3, 4],[5, 6, 7, 8],[9, 10, 11, 12],[13, 14, 15, 16])
A = np.asarray(A)
B = np.arange(16)
B.shape=(4,4)
C = np.arange(4)
C.shape = (4,1)

print("A= \n", A, "\n B = \n", B, "\n C = \n", C)

np.dot(A,B) #Producto punto o escalar

AC = np.dot(A,C)
print(np.shape(A), np.shape(C), np.shape(AC))

A = np.arange(24).reshape((2,3,4))
b = np.arange(4)
C = np.inner(A, b)              #Producto interno entre arreglos 
print(C.shape,"\n", C)

np.linalg.matrix_power(X,2) #Eleve una matriz cuadrada a la potencia (entera) n .

val, vec = np.linalg.eig(X) #Valores y vectores propios de una matriz
print("Val' propios: \n", np.round_(val,2), "\n Vect' propios: \n", np.round_(vec,2))

np.linalg.norm(X) #norma vectorial o matricial

"""##Estadisticas:

"""

X

print(np.amax(X), np.amin(X))

print(np.amax(X, 1), np.amin(X,0))

np.ptp(X)#Rango de la matriz xmax-xmin

np.ptp(X, 1)#Rango por filas

np.ptp(X, 0)#Rango por columnas

np.percentile(X, 50) # Percentil q-esimo

np.percentile(X, 50, 1) #Percentil q-esimo  por filas

np.percentile(X, 50, 0) #Percentil q-esimo  por columnas

np.quantile(X, 0.5 , 0) #Cuantil por columnas

np.median(X, 1) #Mediana por filas

np.mean(X[1,:]) #media aritmetica a lo latrgo de la fila 1

np.std(X) #Desviacion estandar de la matriz

np.var(X)#Varianza de la matriz

X = np.random.randint(0,10, (4,4))
X

np.corrcoef(X) #Coeficiente de correlacion

np.correlate([1, 2, 3], [0, 1, 0.5]) #Correlacion cruzada

x = [-2.1, -1,  4.3]
y = [3,  1.1,  0.12]
X = np.stack((x, y), axis=0)
X

np.cov(X) #AMtriz de covarianza

"""###Histogramas"""

a = np.random.randint(0,10, (4,4)) 
hist, bin_edges = np.histogram(a, density=True)
print(hist,"\n", bin_edges)

plt.hist(a[0,:])

a

v = ([1,2,3,2],[1,4,5,6],[1,4,5,6])

v = np.array(v)
v

x,y=np.histogram(v, density=True)

plt.hist(v[:,1], 4)



"""#2. KERNEL

##2.1 Kernel Lineal

  $k(x,y) = x^T*y+c$, 
 
 donde $x,y \in \mathbb{R}^P; c \in \mathbb{R} \}$
"""

#Con muestras
x = np.asarray([1, 4.5, 0.8, 5.7, 4.2])     #R{P} 1 Dim, P elements
y = np.asarray([0.5, 2.5, 3.8, -5.7, -2.2]) #R{P}  1 Dim, P elements
 
c = 6                                       #Scalar in R

xT= np.transpose(x)           #R{P} 1 Dim, P elements
dot = np.dot(xT, y)           #Scalar in R

k = dot + c                   #Scalar in R
k

"""Con pares de muestras de los conjuntos de muestras $X, Y \in \mathbb{R}^{N \times P}$"""

#Con conjuntos de muestras
N = 5
P = 5

X = np.random.randn(N,P) #R{NxP} 2 Dim, Nxp Elements
Y = np.random.randn(N,P) #R{NxP}    "           "

OUT = np.zeros((N,N))    #R{NxP}  2 Dim, Nxp Elements

for i in range(N):
  XT = np.transpose(X[i, ...])   #R{PxN}  2 Dim, Nxp Elements
  dot = np.dot(XT, Y)           #R{P}
  k = dot + c                   #R
  k
  OUT[i, ...] = k

OUT

"""##2.2  Kernel Polinomial

  $k(x,y) = (\alpha*x^T*y+c)^d$, 
 
 donde $x,y \in \mathbb{R}^P; c, d \in \mathbb{R} \}$
"""

#Con muestras
x = np.asarray([1, 4.5, 0.8, 5.7, 4.2])     #R{P} 1 Dim, P elements
y = np.asarray([0.5, 2.5, 3.8, -5.7, -2.2]) #R{P}  1 Dim, P elements
 
c = 6         #Scalar in R
d = 2         #Scalar in R
a = 3         #Scalar in R

xT= np.transpose(x)           #R{P} 1 Dim, P elements
axT= a*xT                     #R{P} 1 Dim, P elements
axTy= np.dot(axT, y)             #Scalar in R
k = (axTy + c)**d                #Scalar in R
k

"""Con pares de muestras de los conjuntos de muestras $X, Y \in \mathbb{R}^{N \times P}$"""

#Con conjuntos de muestras
N = 5
P = 5

X = np.random.randn(N,P) #R{NxP} 2 Dim, Nxp Elements
Y = np.random.randn(N,P) #R{NxP}    "           "
c = 6         #Scalar in R
d = 2         #Scalar in R
a = 3         #Scalar in R

OUT = np.zeros((N,N))    #R{NxP}  2 Dim, Nxp Elements


for i in range(N):
  XT = np.transpose(X[i, ...])   #R{PxN}  2 Dim, Nxp Elements
  aXT= a*XT                     #R{P} 1 Dim, P elements
  aXTY= np.dot(aXT, Y)             #Scalar in R
  k = (aXTY + c)**d                #Scalar in R
  OUT[i, ...] = k

OUT



"""##2.3 Kernel Gaussiano
$k(x,y) = e^{\big ( -\frac{\lVert x - y \rVert_2^2}{2\sigma^2} \big)}$, donde $x,y \in \mathbb{R}^P; \sigma \in \{s \in \mathbb{R}^+ | s \neq 0  \}$
"""

#Con Muestras
x = np.asarray([1, 4.5, 0.8, 5.7, 4.2])
y = np.asarray([0.5, 2.5, 3.8, -5.7, -2.2])
sigma = 1e-1


x_y = x - y  # 1dim p elemntos
norm = np.linalg.norm(x_y, ord=2) #scalar
norm = norm**2 #sca
div = -1*(norm/(2*sigma**2)) #scarlar
k = np.exp(div) #scalar
k

"""Con pares de muestras de los conjuntos de muestras $X, Y \in \mathbb{R}^{N \times P}$"""

N = 5
P = 5

X = np.random.randn(N,P)
Y = np.random.randn(N,P)

OUT = np.zeros((N,N))

for i in range(N):
  resta = X[i,...] - Y # R{NXP}
  norm = np.linalg.norm(resta, ord=2, axis=1) #R{N}
  norm = norm**2 #R{N}
  div = -1*(norm/(2*sigma**2)) #R{N}
  k = np.exp(div) #R{N}
  OUT[i, ...] = k

OUT



"""##2.4 Kernel exponencial
$k(x,y) = e^{\big ( -\frac{\lVert x - y \rVert}{2\sigma^2} \big)}$, donde $x, y \in \mathbb{R}^P; \sigma \in \{s \in \mathbb{R}^+ | s \neq 0  \}$
"""

#Con Muestras
x = np.asarray([1, 4.5, 0.8, 5.7, 4.2])
y = np.asarray([0.5, 2.5, 3.8, -5.7, -2.2])
sigma = 1e-1


x_y = x - y  # 1dim p elemntos
norm = np.linalg.norm(x_y, ord=2) #scalar

div = -1*(norm/(2*sigma**2)) #scarlar
k = np.exp(div) #scalar
k

"""Con pares de muestras de los conjuntos de muestras $X, Y \in \mathbb{R}^{N \times P}$"""

N = 5
P = 5
sigma = 1e-1

X = np.random.randn(N,P)
Y = np.random.randn(N,P)

OUT = np.zeros((N,N))

for i in range(N):
  resta = X[i,...] - Y # R{NXP}
  norm = np.linalg.norm(resta, ord=2, axis=1) #R{N}
  
  div = -1*(norm/(2*sigma**2)) #R{N}
  k = np.exp(div) #R{N}
  OUT[i, ...] = k #R{NxN}

OUT

"""##2.5 Kernel laplaciano 
$k(x,y) =  e^{\big ( -\frac{\lVert x - y \rVert}{\sigma} \big)}$, donde $x, y \in \mathbb{R}^P; \sigma \in \{s \in \mathbb{R}^+ | s \neq 0  \}$
"""

#Con Muestras
x = np.asarray([1, 4.5, 0.8, 5.7, 4.2])
y = np.asarray([0.5, 2.5, 3.8, -5.7, -2.2])
sigma = 1e-1


x_y = x - y  # 1dim p elemntos
norm = np.linalg.norm(x_y, ord=2) #scalar

div = -1*(norm/(sigma)) #scarlar
k = np.exp(div) #scalar
k

"""Con pares de muestras de los conjuntos de muestras $X, Y \in \mathbb{R}^{N \times P}$"""

N = 5
P = 5
sigma = 1e-1

X = np.random.randn(N,P)
Y = np.random.randn(N,P)

OUT = np.zeros((N,N))

for i in range(N):
  resta = X[i,...] - Y # R{NXP}
  norm = np.linalg.norm(resta, ord=2, axis=1) #R{N}
  
  div = -1*(norm/(sigma)) #R{N}
  k = np.exp(div) #R{N}
  OUT[i, ...] = k #R{NxN}

OUT



"""##2.6 Kernel ANOVA

#$k(x,y) = \sum_{k=1}^{n}e^{(-\sigma(x^k - y^k)^2)^d} $

"""

#Con Muestras
x = np.asarray([1, 4.5, 0.8, 5.7, 4.2])
y = np.asarray([0.5, 2.5, 3.8, -5.7, -2.2])
sigma = 1e-1

n = len(x)
k=1
d=2
kernel = 0
for k in range(n):
  xk_yk2 = (x**k - y**k)**2  # 1dim p elemntos
  _s_xk_yk2 = (-sigma*xk_yk2)**d

  ker = np.exp(_s_xk_yk2) #scalar
  kernel=kernel+ker
kernel

"""Con pares de muestras de los conjuntos de muestras $X, Y \in \mathbb{R}^{N \times P}$"""

N = 5
P = 5
sigma = 1e-1
n = len(x)
k=1
d=2

X = np.random.randn(N,P)
Y = np.random.randn(N,P)

OUT = np.zeros((N,N))

for i in range(N):
 for k in range(n):
  xk_yk2 = (X[i, ...]**k - Y**k)**2  # 1dim p elemntos
  _s_xk_yk2 = (-sigma*xk_yk2)**d

  ker = np.exp(_s_xk_yk2) #scalar
  kernel=kernel+ker
  OUT[i, ...] = kernel[i,...] #R{NxN}
  OUT.shape

"""##2.7 Kernel de tangente hiperbolica (sigmoide).

#$k(x,y) = {tanh(\alpha x^Ty+c)} $

"""

#Con muestras
x = np.asarray([1, 4.5, 0.8, 5.7, 4.2])     #R{P} 1 Dim, P elements
y = np.asarray([0.5, 2.5, 3.8, -5.7, -2.2]) #R{P}  1 Dim, P elements
 
c = 6         #Scalar in R
d = 2         #Scalar in R
a = 1/ len(x)#Scalar in R (ALPHA)

xT= np.transpose(x)           #R{P} 1 Dim, P elements
axT= a*xT            #R{P} 1 Dim, P elements
axTy= np.dot(axT, y) #Scalar in R

tanh = np.tanh(axTy + c)   #Scalar in R     
k = tanh             #Scalar in R
k

"""Con pares de muestras de los conjuntos de muestras $X, Y \in \mathbb{R}^{N \times P}$"""

#Con conjuntos de muestras
N = 5
P = 5

X = np.random.randn(N,P) #R{NxP} 2 Dim, Nxp Elements
Y = np.random.randn(N,P) #R{NxP}    "           "
c = 6         #Scalar in R
d = 2         #Scalar in R
a = 1/len(x)         #Scalar in R

OUT = np.zeros((N,N))    #R{NxP}  2 Dim, Nxp Elements


for i in range(N):
  XT = np.transpose(X[i, ...])   #R{PxN}  2 Dim, Nxp Elements
  aXT= a*XT                     #R{P} 1 Dim, P elements
  aXTY= np.dot(aXT, Y)             #Scalar in R
  tan = np.tanh(aXTY + c)               #Scalar in R
  k = tan             #Scalar in R
  OUT[i, ...] = k

OUT

"""##2.8 Nucleo Cuadratico Racional.

$k(x,y) = 1 - { \frac{\lVert x - y \rVert^2}{\lVert x - y \rVert^2 + c } \big)}$, donde $x,y \in \mathbb{R}^P; \sigma \in \{c \in \mathbb{R}  \}$
"""

#Con Muestras
x = np.asarray([1, 4.5, 0.8, 5.7, 4.2])
y = np.asarray([0.5, 2.5, 3.8, -5.7, -2.2])


x_y = x - y  # 1dim p elemntos
norm = np.linalg.norm(x_y, ord=2) #scalar
norm2 = norm**2

div = norm2/(norm2 + c) #scarlar
resta = 1 - div
k = resta #scalar
k

"""Con pares de muestras de los conjuntos de muestras $X, Y \in \mathbb{R}^{N \times P}$"""

N = 5
P = 5
sigma = 1e-1

X = np.random.randn(N,P)
Y = np.random.randn(N,P)

OUT = np.zeros((N,N))

for i in range(N):
  X_Y = X[i,...] - Y # R{NXP}
  norm = np.linalg.norm(X_Y, ord=2, axis=1) #R{N}
  norm2 = norm**2
  
  div = norm2/(norm2 + c) #R{N}
  resta = 1 - div
  k = resta #R{N}
  OUT[i, ...] = k #R{NxN}

OUT



"""##2.9 Nucleo multicuadratico
$k(x,y) = \sqrt{\lVert x - y \rVert^2 + c^2}$, donde $x,y \in \mathbb{R}^P;  \{c \in \mathbb{R}  \}$
"""

#Con Muestras
x = np.asarray([1, 4.5, 0.8, 5.7, 4.2])
y = np.asarray([0.5, 2.5, 3.8, -5.7, -2.2])


x_y = x - y  # 1dim p elemntos
norm = np.linalg.norm(x_y, ord=2) #scalar
norm2 = norm**2

suma = norm2 + c**2 #scarlar
raiz = np.sqrt(suma)
k = raiz #scalar
k

"""Con pares de muestras de los conjuntos de muestras $X, Y \in \mathbb{R}^{N \times P}$"""

N = 5
P = 5

X = np.random.randn(N,P)
Y = np.random.randn(N,P)

OUT = np.zeros((N,N))

for i in range(N):
  X_Y = X[i,...] - Y # R{NXP}
  norm = np.linalg.norm(X_Y, ord=2, axis=1) #R{N}
  norm2 = norm**2
  
  suma = norm2 + c**2 #R{N}
  raiz = np.sqrt(suma)
  k = raiz #R{N}
  OUT[i, ...] = k #R{NxN}

OUT

"""##2.10 Nucleo multicuadratico inverso

$k(x,y) ={ \frac{1}{\sqrt{\lVert x - y \rVert^2 + c^2}} \big)}$, donde $x,y \in \mathbb{R}^P; \{c \in \mathbb{R}  \}$
"""

#Con Muestras
x = np.asarray([1, 4.5, 0.8, 5.7, 4.2])
y = np.asarray([0.5, 2.5, 3.8, -5.7, -2.2])


x_y = x - y  # 1dim p elemntos
norm = np.linalg.norm(x_y, ord=2) #scalar
norm2 = norm**2

suma = norm2 + c**2 #scarlar
raiz = np.sqrt(suma)
k = 1/raiz #scalar
k

"""Con pares de muestras de los conjuntos de muestras $X, Y \in \mathbb{R}^{N \times P}$"""

N = 5
P = 5

X = np.random.randn(N,P)
Y = np.random.randn(N,P)

OUT = np.zeros((N,N))

for i in range(N):
  X_Y = X[i,...] - Y # R{NXP}
  norm = np.linalg.norm(X_Y, ord=2, axis=1) #R{N}
  norm2 = norm**2
  
  suma = norm2 + c**2 #R{N}
  raiz = np.sqrt(suma)
  k = 1/raiz #R{N}
  OUT[i, ...] = k #R{NxN}

OUT



"""#CLASE KERNEL:"""

class Kernel():
  """
  Esta Clase permite evaluar los 10 kernels aneriores

  """
  def __init__(self, a, c, d): #constructor
    pass

############ Kernel Lineal #####################

  def lineal_muestras(self, x , y):  #Metodo kernel lineal para muestras en R^P
    """
    Retorna kernel lineal para un par de muestras x e y en R^p
    R^p -> R

    """
    xT= np.transpose(x)           #R{P} 1 Dim, P elements
    dot = np.dot(xT, y)           #Scalar in R
    k = dot + c                   #Scalar in R
    return k

  def lineal_conj_muestras(self, X, Y):  #Metodo kernel lineal para conjuntos de muestras de tamaño NxP
    """
    Retorna kernel lineal para los conjuntos de muestras X e Y en R^NxP
    R^NxP -> R^NxN

    """
    OUT = np.zeros((N,N))    #R{NxP}  2 Dim, Nxp Elements

    for i in range(N):
      XT = np.transpose(X[i, ...])   #R{PxN}  2 Dim, Nxp Elements
      dot = np.dot(XT, Y)           #R{P}
      k = dot + c                   #R
      k
      OUT[i, ...] = k
    return OUT

########## Kernel polinomial ###################

  def pol_muestras(self, x , y):
    """
    Retorna kernel polinomial para un par de muestras x e y en R^p
    R^p -> R
    """
    xT= np.transpose(x)           #R{P} 1 Dim, P elements
    axT= a*xT                     #R{P} 1 Dim, P elements
    axTy= np.dot(axT, y)             #Scalar in R
    k = (axTy + c)**d                #Scalar in R
    return k

  def pol_conj_muestras(self, X, Y):
    """
    Retorna kernel polinomial para los conjuntos de muestras X e Y en R^NxP
    R^NxP -> R^NxN
    """
    OUT = np.zeros((N,N))    #R{NxP}  2 Dim, Nxp Elements
    for i in range(N):
      XT = np.transpose(X[i, ...])   #R{PxN}  2 Dim, Nxp Elements
      aXT= a*XT                     #R{P} 1 Dim, P elements
      aXTY= np.dot(aXT, Y)             #Scalar in R
      k = (aXTY + c)**d                #Scalar in R
      OUT[i, ...] = k
    return OUT
  

########## Kernel Gaussiano ####################

  def gaus_muestras(self, x, y, sigma):
    """
    Retorna kernel gaussiano para un par de muestras x e y en R^p
    R^p -> R
    """
  
    x_y = x - y  # 1dim p elemntos
    norm = np.linalg.norm(x_y, ord=2) #scalar
    norm = norm**2 #sca
    div = -1*(norm/(2*sigma**2)) #scarlar
    k = np.exp(div) #scalar
    return k

  def gaus_conj_muestras(self, X, Y, sigma):
    """
    Retorna kernel gaussiano para los conjuntos de muestras X e Y en R^NxP
    R^NxP -> R^NxN
    """

    OUT = np.zeros(np.shape(X))
    for i in range(N):
      resta = X[i,...] - Y # R{NXP}
      norm = np.linalg.norm(resta, ord=2, axis=1) #R{N}
      norm = norm**2 #R{N}
      div = -1*(norm/(2*sigma**2)) #R{N}
      k = np.exp(div) #R{N}
      OUT[i, ...] = k
    return OUT
  
########## Kernel Exponencial ##################

  def exp_muestras(self, x, y, sigma):
    """
    Retorna kernel exponencial para un par de muestras x e y en R^p
    R^p -> R
    """
    x_y = x - y  # 1dim p elemntos
    norm = np.linalg.norm(x_y, ord=2) #scalar
    div = -1*(norm/(2*sigma**2)) #scarlar
    k = np.exp(div) #scalar
    return k

  def exp_conj_muestras(self, X, Y, sigma):
    """
    Retorna kernel exponencial para los conjuntos de muestras X e Y en R^NxP
    R^NxP -> R^NxN
    """
    OUT = np.zeros(np.shape(X))
    for i in range(len(X[...,0])):
      resta = X[i,...] - Y # R{NXP}
      norm = np.linalg.norm(resta, ord=2, axis=1) #R{N}
  
      div = -1*(norm/(2*sigma**2)) #R{N}
      k = np.exp(div) #R{N}
      OUT[i, ...] = k #R{NxN}
    return OUT
    
########## Kernel Laplaciano ###################

  def laplace_muestras(self, x, y, sigma):
    """
    Retorna kernel laplaciano para un par de muestras x e y en R^p
    R^p -> R
    """
    x_y = x - y  # 1dim p elemntos
    norm = np.linalg.norm(x_y, ord=2) #scalar

    div = -1*(norm/(sigma)) #scarlar
    k = np.exp(div) #scalar
    return k

  def laplace_conj_muestras(self, X, Y, sigma):
    """
    Retorna kernel laplaciano para los conjuntos de muestras X e Y en R^NxP
    R^NxP -> R^NxN
    """
    OUT = np.zeros(np.shape(X))
    for i in range(len(X[...,0])):
      resta = X[i,...] - Y # R{NXP}
      norm = np.linalg.norm(resta, ord=2, axis=1) #R{N}
      div = -1*(norm/(sigma)) #R{N}
      k = np.exp(div) #R{N}
      OUT[i, ...] = k #R{NxN}
    return OUT
  
########## Kernel Anova ########################

  def anova_muestras(self, x, y, sigma):
    """
    Retorna kernel anova para un par de muestras x e y en R^p
    R^p -> R
    """
    n = len(x)
    k=1
    d=2
    kernell = 0
    for k in range(len(x)):
      xk_yk2 = (x**k - y**k)**2  # 1dim p elemntos
      _s_xk_yk2 = (-sigma*xk_yk2)**d
      ker = np.exp(_s_xk_yk2) #scalar
      kernell = kernell + ker
    return kernell

  def anova_conj_muestras(self, X, Y, sigma):
    """
    Retorna kernel anova para los conjuntos de muestras X e Y en R^NxP
    R^NxP -> R^NxN
    """
    OUT = np.zeros(np.shape(X))
    kernell = 0
    for i in range(len(X[...,0])):
      for k in range(len(X[...,0])):
       xk_yk2 = (X[i, ...]**k - Y**k)**2  # 1dim p elemntos
       _s_xk_yk2 = (-sigma*xk_yk2)**d
       ker = np.exp(_s_xk_yk2) #scalar
       kernell=kernell+ker
       OUT[i, ...] = kernell[i,...] #R{NxN}
    return OUT

########## Kernel Tangente hiperbolica (sigmoide) #########

  def tanh_muestras(self, x, y):
    """
    Retorna kernel tangente hiperbolico para un par de muestras x e y en R^p
    R^p -> R
    """
    a = 1/ len(x)#Scalar in R (ALPHA)
    xT= np.transpose(x)           #R{P} 1 Dim, P elements
    axT= a*xT            #R{P} 1 Dim, P elements
    axTy= np.dot(axT, y) #Scalar in R

    tanh = np.tanh(axTy + c)   #Scalar in R     
    k = tanh             #Scalar in R
    return k

  def tanh_conj_muestras(self, X, Y):
    """
    Retorna kernel tangente hiperbolico para los conjuntos de muestras X e Y en R^NxP
    R^NxP -> R^NxN
    """
    OUT = np.zeros(np.shape(X))
    a = 1/len(x)         #Scalar in R
    for i in range(len(X[...,0])):
      XT = np.transpose(X[i, ...])   #R{PxN}  2 Dim, Nxp Elements
      aXT= a*XT                     #R{P} 1 Dim, P elements
      aXTY= np.dot(aXT, Y)             #Scalar in R
      tan = np.tanh(aXTY + c)               #Scalar in R
      k = tan             #Scalar in R
      OUT[i, ...] = k
    return OUT

########## Kernel cuadratico racional ############
  def cuad_racional_muestras(self, x, y):
    """
    Retorna kernel cuadratico racional para un par de muestras x e y en R^p
    R^p -> R
    """
    x_y = x - y  # 1dim p elemntos
    norm = np.linalg.norm(x_y, ord=2) #scalar
    norm2 = norm**2

    div = norm2/(norm2 + c) #scarlar
    resta = 1 - div
    k = resta #scalar
    return k

  def cuad_racional_conj_muestras(self, X, Y):
    """
    Retorna kernel cuadratico racional para los conjuntos de muestras X e Y en R^NxP
    R^NxP -> R^NxN
    """
    OUT = np.zeros(np.shape(X))
    for i in range(len(X[...,0])):
      X_Y = X[i,...] - Y # R{NXP}
      norm = np.linalg.norm(X_Y, ord=2, axis=1) #R{N}
      norm2 = norm**2
  
      div = norm2/(norm2 + c) #R{N}
      resta = 1 - div
      k = resta #R{N}
      OUT[i, ...] = k #R{NxN}
    return OUT

########## Kernel multicuadratico ################
  def multicuadratico_muestras(self, x, y):
    """
    Retorna kernel multicuadratico para un par de muestras x e y en R^p
    R^p -> R
    """
    x_y = x - y  # 1dim p elemntos
    norm = np.linalg.norm(x_y, ord=2) #scalar
    norm2 = norm**2

    suma = norm2 + c**2 #scarlar
    raiz = np.sqrt(suma)
    k = raiz #scalar
    return k

  def multicuadratico_conj_muestras(self, X, Y):
    """
    Retorna kernel multicuadratico para los conjuntos de muestras X e Y en R^NxP
    R^NxP -> R^NxN
    """
    OUT = np.zeros(np.shape(X))
    for i in range(len(X[...,0])):
      X_Y = X[i,...] - Y # R{NXP}
      norm = np.linalg.norm(X_Y, ord=2, axis=1) #R{N}
      norm2 = norm**2
  
      suma = norm2 + c**2 #R{N}
      raiz = np.sqrt(suma)
      k = raiz #R{N}
      OUT[i, ...] = k #R{NxN}
    return OUT

########## Kernel Multicuadratico inverso ######
  def multicuadratico_inv_muestras(self, x, y):
    """
    Retorna kernel multicuadratico inverso para un par de muestras x e y en R^p
    R^p -> R
    """
    x_y = x - y  # 1dim p elemntos
    norm = np.linalg.norm(x_y, ord=2) #scalar
    norm2 = norm**2

    suma = norm2 + c**2 #scarlar
    raiz = np.sqrt(suma)
    k = 1/raiz #scalar
    return k

  def multicuadratico_inv_conj_muestars(self, X, Y):
    """
    Retorna kernel multicuadratico inverso para los conjuntos de muestras X e Y en R^NxP
    R^NxP -> R^NxN
    """
    OUT = np.zeros(np.shape(X))
    for i in range(len(X[...,0])):
      X_Y = X[i,...] - Y # R{NXP}
      norm = np.linalg.norm(X_Y, ord=2, axis=1) #R{N}
      norm2 = norm**2
  
      suma = norm2 + c**2 #R{N}
      raiz = np.sqrt(suma)
      k = 1/raiz #R{N}
      OUT[i, ...] = k #R{NxN}
    return OUT

"""##Llamado a la clase:"""

kernel = Kernel(6, 2, 2) #CREO EL OBJETO DE CLASE KERNEL atributos (alpha, c, d)

x = np.asarray([1.1, 3.5, 1.8, 3.7, 5.2])     #R{P} 1 Dim, P elements   MUESTRAS
y = np.asarray([0.5, 1.5, 4.8, -3.7, -6.2]) #R{P}  1 Dim, P elements  MUESTRAS
X = np.random.randn(5,5) #R{NxP} 2 Dim, Nxp Elements CONJ_MUESTRAS
Y = np.random.randn(5,5) #R{NxP}   ""                  ""

"""###Kernel lineal"""

kernel.lineal_muestras(x,y)

kernel.lineal_conj_muestras(X, Y)

"""###Kernel Polinomial"""

kernel.pol_muestras(x, y)

kernel.pol_conj_muestras(X, Y)

"""###Kernel Gaussiano"""

kernel.gaus_muestras(x, y, 1e-1)

kernel.gaus_conj_muestras(X, Y, 1e-1)

"""###Kernel Exponencial"""

kernel.exp_muestras(x, y, 1e-1)

kernel.exp_conj_muestras(X, Y, 1e-1)

"""###Kernel Laplaciano"""

kernel.laplace_muestras(x,y, 1e-1)

kernel.laplace_conj_muestras(X, Y, 1e-1)

"""###Kernel ANOVA

"""

kernel.anova_muestras(x, y, 1e-1)

kernel.anova_conj_muestras(X, Y, 1e-1)

"""###Kernel Tangente Hiperbolica (sigmoide)"""

kernel.tanh_muestras(x, y)

kernel.tanh_conj_muestras(X, Y)

"""###Kernel cuadratico Racional"""

kernel.cuad_racional_muestras(x, y)

kernel.cuad_racional_conj_muestras(X, Y)

"""###Kernel Multicuadratico"""

kernel.multicuadratico_muestras(x, y)

kernel.multicuadratico_conj_muestras(X, Y)

"""###Kernel Multicuadratico Inverso"""

kernel.multicuadratico_inv_muestras(x, y)

kernel.multicuadratico_inv_conj_muestars(X, Y)